{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f229ae",
   "metadata": {},
   "source": [
    "## The notebook contains 3 main parts:\n",
    "\n",
    "For some models, I simplly fitted the data and only look at the accuracy score. For three methods that are relatveily more complex: GridSearch CV + Pipeline, Stacking, and NN, I included more detailed evaluation.\n",
    "\n",
    "### Model validation\n",
    "- Cross validation (KFold)\n",
    "- GridSearch CV \n",
    "- Pipeline\n",
    "- GridSearch CV + Pipeline to fit 5 folds for each of 270 candidates, totalling 1350 fits (with detailed evaluation)\n",
    "  \n",
    "### Ensemble learning\n",
    "- Boosting\n",
    "- Stacking (with detailed evaluation)\n",
    "\n",
    "### NN for a binary classification task (with detailed evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71671d7a-713c-4ef3-8d2e-8f74ba684d14",
   "metadata": {},
   "source": [
    "# Part I: Model validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3e5f6",
   "metadata": {},
   "source": [
    "## Cross validation (KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "eb9337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f9849c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('C:/Users/Victoria/OneDrive/文档/Dropbox/Machine Learning Python/Project/data_EDA.csv') \n",
    "#generate next year GDP\n",
    "df_aggregated = df.groupby('Year')['gdp'].mean().reset_index()\n",
    "df_aggregated['next_year_gdp'] = df_aggregated['gdp'].shift(-1)\n",
    "\n",
    "# Merge the lagged GDP data back to the original DataFrame\n",
    "df = df.merge(df_aggregated[['Year', 'next_year_gdp']], on='Year', how='left')\n",
    "df['next_year_gdp_grow_dummy'] = np.where(df['next_year_gdp'] > 0, 1, 0)\n",
    "\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c550f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Year', 'gdp', 'Title', 'Description', 'gdp_normal',  'lag_gdp','gdp_grow_dummy','source',\n",
    "                     'Tokenized_Description', 'Stem_Lemm_Description', 'Processed_Words', 'Joined_Words','next_year_gdp','next_year_gdp_grow_dummy'])  # Features\n",
    "y = df['next_year_gdp_grow_dummy']  # Target variable\n",
    "y = y.reset_index(drop=True) # Reset the index of y to make it align with integer locations\n",
    "X = X.reset_index(drop=True) # Reset the index of y to make it align with integer locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1f659c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5920, 30), (5920,))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88cb04",
   "metadata": {},
   "source": [
    "- Tain/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f8ceb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4b7aa637",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, \n",
    "                                                    random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9df6c0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3552, 30), (3552,), Counter({1: 3186, 0: 366}))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, Counter(y_train)\n",
    "# 3552 samples, and each sample has 30 features. \n",
    "# Here, 1 represents the class where the GDP is predicted to grow the next year, and 0 represents the class where it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "96c206a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2368, 30), (2368,), Counter({1: 2129, 0: 239}))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42858a",
   "metadata": {},
   "source": [
    "- Before doing K-folds, this fits a classifier on training data and test on testing data using a logistic regression model, which has achieved an accuracy score of approximately 0.902 on the test set. This means that the model correctly predicted whether the GDP would grow the next year or not for 90.2% of the cases in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2872f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1af9d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024493243243243"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d8c65",
   "metadata": {},
   "source": [
    "### Option-1: directly apply cross validation to get the model validation scores\n",
    "\n",
    "I am using 10-fold cross-validation. In this method, the dataset is divided into 10 folds. During the cross-validation process, the model is trained 10 times, each time using 9 of the 10 folds for training and the remaining fold for testing. \n",
    "\n",
    "In reviewing the recall scores from the 10-fold cross-validation, I observed that 6 out of 10 folds yielded perfect scores of 1.0, indicating that my logistic regression model successfully identified all instances of next year's GDP growth binary variable without missing any in these folds. However, in the remaining folds, the scores were slightly lower. These scores suggest that while the model is generally reliable, there are instances where it fails to capture all positive cases, which may be due to variations in data characteristics or model sensitivity across different subsets of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "82bf6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "197107b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=10, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3cc761be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99811676, 0.99811676, 0.92655367, 0.95291902])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fd920",
   "metadata": {},
   "source": [
    "### Option-2: apply KFold to split the data into K-folds and then do cross validation on the k-fold data\n",
    "\n",
    "The scores are similar to the option above. The difference is due to the sequence of procedures in splitting data.   Since the original dataset appears to be significantly imbalanced towards class 1 (postive next year gdp groth, this inherent imbalance means any random or even somewhat stratified sampling without specific techniques to address imbalance will reflect this disparity, as indicated by the difference train labels count and \n",
    "Test labels cout for each folds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3d1379b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "742e43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels count: Counter({1: 4777, 0: 551})\n",
      "Test labels count: Counter({1: 538, 0: 54})\n",
      "Train labels count: Counter({1: 4789, 0: 539})\n",
      "Test labels count: Counter({1: 526, 0: 66})\n",
      "Train labels count: Counter({1: 4778, 0: 550})\n",
      "Test labels count: Counter({1: 537, 0: 55})\n",
      "Train labels count: Counter({1: 4787, 0: 541})\n",
      "Test labels count: Counter({1: 528, 0: 64})\n",
      "Train labels count: Counter({1: 4795, 0: 533})\n",
      "Test labels count: Counter({1: 520, 0: 72})\n",
      "Train labels count: Counter({1: 4778, 0: 550})\n",
      "Test labels count: Counter({1: 537, 0: 55})\n",
      "Train labels count: Counter({1: 4780, 0: 548})\n",
      "Test labels count: Counter({1: 535, 0: 57})\n",
      "Train labels count: Counter({1: 4786, 0: 542})\n",
      "Test labels count: Counter({1: 529, 0: 63})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n",
      "Train labels count: Counter({1: 4781, 0: 547})\n",
      "Test labels count: Counter({1: 534, 0: 58})\n"
     ]
    }
   ],
   "source": [
    "# apply KFold split on the dataset\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    # Use iloc to access rows based on integer indices\n",
    "    train_y = y.iloc[train_idx]\n",
    "    test_y = y.iloc[test_idx]\n",
    "    print(\"Train labels count:\", Counter(train_y))\n",
    "    print(\"Test labels count:\", Counter(test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "47756ed6-0dc2-43b5-9fa9-9614a57c6045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 4781, 0: 547}), Counter({1: 534, 0: 58}))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y[train_idx]), Counter(y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f5a5721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.9904943 , 0.99627561, 1.        , 0.99230769,\n",
       "       0.9981378 , 1.        , 0.99432892, 0.99811676, 0.98689139])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=kf, scoring='recall') \n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d555629",
   "metadata": {},
   "source": [
    "### Option-3: apply stratified KFold to keep the class distribution\n",
    "\n",
    "In Stratified K-Fold, each fold is made by preserving the percentage of samples for each class. This means that each fold will have approximately the same percentage of samples of each class as the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bce9988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d0ba6dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels count: Counter({1: 4783, 0: 545})\n",
      "Test labels count: Counter({1: 532, 0: 60})\n",
      "Train labels count: Counter({1: 4783, 0: 545})\n",
      "Test labels count: Counter({1: 532, 0: 60})\n",
      "Train labels count: Counter({1: 4783, 0: 545})\n",
      "Test labels count: Counter({1: 532, 0: 60})\n",
      "Train labels count: Counter({1: 4783, 0: 545})\n",
      "Test labels count: Counter({1: 532, 0: 60})\n",
      "Train labels count: Counter({1: 4783, 0: 545})\n",
      "Test labels count: Counter({1: 532, 0: 60})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n",
      "Train labels count: Counter({1: 4784, 0: 544})\n",
      "Test labels count: Counter({1: 531, 0: 61})\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X,y):\n",
    "    # Use iloc to access rows based on integer indices\n",
    "    train_y = y.iloc[train_idx]\n",
    "    test_y = y.iloc[test_idx]\n",
    "    print(\"Train labels count:\", Counter(train_y))\n",
    "    print(\"Test labels count:\", Counter(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cf642115-831e-4d7c-a70e-7bea51498197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9981203 , 0.9943609 , 0.9981203 , 0.9924812 , 0.9962406 ,\n",
       "       0.99811676, 0.99435028, 0.99623352, 0.99811676, 0.99623352])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=kf, scoring='recall') \n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742ecfc-52d7-47ed-a724-2b7ef9dc0b5c",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "Using cross-validation methods yields higher scores then simply applying logistic regression once.  Now that each fold serves as a test set at some point, and the rest of the data as training data, this reduces the variance in the estimated performance metrics and providing a more reliable measure of the model’s ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b68020",
   "metadata": {},
   "source": [
    "### Option-4: Leave One Out strategy, useful when don't have enough data\n",
    "\n",
    "For this one, since my sample size is not very small. Calculating the score is time-consuming. So the score will not reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cf5f017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3c134a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: [   1    2    3 ... 5917 5918 5919] \n",
      "Test samples: [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in loo.split(X):\n",
    "    print(\"Train samples: %s \\nTest samples: %s\\n\" % (train_idx, test_idx))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b42f38-1201-4bbe-b86b-8bd867e10087",
   "metadata": {},
   "source": [
    "clf = LogisticRegression(random_state=42)\r\n",
    "scores = []\r\n",
    "\r\n",
    "for train_idx, test_idx in loo.split(X):\r\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\r\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\r\n",
    "\r\n",
    "    # Fit the model\r\n",
    "    clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "    # Predict the test set\r\n",
    "    y_pred = clf.predict(X_test)\r\n",
    "\r\n",
    "    # Evaluate the prediction\r\n",
    "    score = accuracy_score(y_test, y_pred)\r\n",
    "    scores.append(score)\r\n",
    "\r\n",
    "    # Optionally, break after the first to check the se*#up\r\n",
    "    # break\r\n",
    "\r\n",
    "# Calculate the mean accuracy across all LOO tests\r\n",
    "mean_accuracy = np.mean(scores)\r\n",
    "print(\"LOO CV Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439de95",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- search for the best hyperparameter settings\n",
    "- 'C':[0.1, 1, 10]: This is the inverse of regularization strength; smaller values specify stronger regularization. By adjusting C, I control the trade-off between achieving a lower-variance, higher-bias model with strong regularization (C is small), and a lower-bias, higher-variance model with weaker regularization (C is large). \n",
    "The values starsg from a relatively strong regularization (0.1) to a weaker one (10)\n",
    "- solver: ['liblinear']\r\n",
    "This specifies the algorithm to use in the optimization problem. liblinear is a good choice for small datasets and binary classification problem\n",
    "- penalty: ['l1', 'l2'] (Lasso regularization) produce sparse models with fewer non-zero coefficients, effectively performing feature selection by driving some coefficient estimates to exactly zero. (Ridge regularization) shrinks the coefficients but never sets them to zero. It spreads the penalty across all coefficients, which helps to improve model robustness by avoiding the undue influence of any single feature.. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "43e44f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2795a927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000, penalty=&#x27;l1&#x27;, random_state=42,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000, penalty=&#x27;l1&#x27;, random_state=42,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000, penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l1',solver='liblinear',random_state=42,max_iter=2000)\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d37fd400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;),\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;),\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.1, 1, 10], 'penalty': ('l1', 'l2'),\n",
       "                         'solver': ['liblinear']})"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "parameters = {'penalty':('l1', 'l2'), \n",
    "              'C':[0.1, 1, 10],\n",
    "              'solver': ['liblinear']} # 2*3*1 = 6 combinations of parameters\n",
    "\n",
    "grid_cv = GridSearchCV(estimator = lr, param_grid = parameters, cv=5)\n",
    "\n",
    "grid_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "604ba8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_C',\n",
       " 'param_penalty',\n",
       " 'param_solver',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_cv.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "829d16ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01914692, 0.0217422 , 0.01835032, 0.01795235, 0.0167532 ,\n",
       "       0.02293901])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.cv_results_['mean_fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0531db0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87702703, 0.87381757, 0.86131757, 0.86131757, 0.85929054,\n",
       "       0.85962838])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e9921119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89780405, 0.89780405, 0.89780405, 0.89780405, 0.89780405,\n",
       "       0.89780405])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.cv_results_['split0_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fb04a51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "99fc7420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0724b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770270270270271"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84f535-3e36-483b-8f9c-202e244f5f08",
   "metadata": {},
   "source": [
    "#### Discussion\r\n",
    "\r\n",
    "##### Best Parameters\r\n",
    "\r\n",
    "- **C: 0.1** — This value suggests that stronger regularization helps to prevent overfitting and improves the model's generalization capability on the dataset.\r\n",
    "\r\n",
    "- **Penalty: 'l1'** — This makes sense since the dataset contains some features that are irrelevant for prediction. L1 regularization can reduce their coefficients to zero, effectively performing feature selection.\r\n",
    "\r\n",
    "- **Solver: 'liblinear'** — This solver is suitable for binary classification problems and supports L1 regularization, which aligns with the finding#s.\r\n",
    "\r\n",
    "#### Performance\r\n",
    "\r\n",
    "- The best score of 0.877 (or 87.70%) is lower than the previous K-Folds validation scores. This discrepancy may be due to the parameters chosen during the GridSearchCV, particularly the L1 penalty and strong regularization, which emphasize model simplicity and generalization over fitting to potentially more complex patterns in the training data.\r\n",
    "gs.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c9bb9",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "In logistic regression, using StandardScaler helps in speeding up the convergence of the stochastic gradient descent algorithm used in the background and can also lead to a more stable model.\r\n",
    "Accuracy of 90.33% suggests that the model performs well on this particular test set, accurately predicting the target variable most of the tim. But due to the imbalance nature, this score does not mean anything.e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "71e72898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8414cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('logistic', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "37b769cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;logistic&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;logistic&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()),\n",
       "                ('logistic', LogisticRegression())])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "126a3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903293918918919"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c0deb",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning using GridSearchCV and pipeline \n",
    "-  text classification\n",
    "- jointly find the best hyperparameters in each step of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6ebbba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "55f0df6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43            Climate change is above all an equity issue\n",
      "44      Favourable terms of trade provide much needed ...\n",
      "45      UN GA adopts resolution to graduate these thre...\n",
      "46      Davos-style dialogue on the theme of the Confe...\n",
      "47      To address the existing barriers to the adopti...\n",
      "                              ...                        \n",
      "6526    This Selected Issues paper discusses interacti...\n",
      "6527    This Selected Issues paper summarizes achievem...\n",
      "6528    This Selected Issues paper aims to take stock ...\n",
      "6529    Economic developments over the past two years ...\n",
      "6530    The U.S. is in the midst of an unprecedented s...\n",
      "Name: Description, Length: 5920, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55391c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uruguay has consolidated economic gains, supported by strong macroeconomic policies and a broadly favorable external environment. Growth has exceeded expectations, unemployment has reached record lows, and poverty has continued to fall, while economic vulnerabilities have been significantly reduced. Despite strong credit growth, financial system soundness indicators have improved, showing a well-capitalized banking system, low nonperforming loan ratios and high liquidity levels. Executive Directors have welcomed the measures the authorities have taken to reduce inflationary pressures, including increases in the policy rate and banks’ reserve requirements and tax administrative measures.'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4888]['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b1504",
   "metadata": {},
   "source": [
    "### Define a pipeline: text feature extraction + classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "559e8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "custom_stop_words = set(ENGLISH_STOP_WORDS).union({'gdp','2018','2019','2020','azevêdo','2021','roberto','conference','takes','september','countries','members','forum','programme','december','notified','organization','certain','ministerial','chf','china','basis','general','march','place','external','2022','2023','2017','2016','unit','2015','2014','2013','2012','2011','2010','2009','2008','2007','2006','2005','2004','2003','2002','2001','2000','highlight','includ','agreement','19','organ','financ','domest','trade','larg','structur','fund','pascal','lami','implement','committe','region','recent','medium','octob','work','ass','outlook','framework','gpd','project','polici','state','new','consult','financi','expect','negoti','develop','product','economi','wa','govern','world','bank','review','extern','intern','said','discus','ha','thi','wto','countri','percent','report','gener','growth','director','global','author','member','econom','articl','iv','measure','year','market','public','sector','measur','term','meet'})\n",
    "custom_stop_words = list(custom_stop_words)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer(min_df=5, max_df=0.8, ngram_range=(1,1), binary=False, stop_words=custom_stop_words)),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"clf\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "92f0c96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect',\n",
       "  CountVectorizer(max_df=0.8, min_df=5,\n",
       "                  stop_words=['once', 'structur', 'yet', 'roberto', 'own',\n",
       "                              'bottom', 'hereafter', 'both', 'he', 'because',\n",
       "                              'whenever', '2017', 'otherwise', 'whoever', '2012',\n",
       "                              'serious', 'well', 'bill', 'empty', 'from',\n",
       "                              'although', 'azevêdo', 'thus', 'unit', 'one',\n",
       "                              'fill', 'along', 'chf', 're', 'perhaps', ...])),\n",
       " ('tfidf', TfidfTransformer()),\n",
       " ('clf', LogisticRegression())]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af66cd7",
   "metadata": {},
   "source": [
    "### Explore the parameters: search over different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7527f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': [0.5, 0.75, 1.0],\n",
    "    'vect__min_df': [1, 2, 5],  \n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features': [None, 1000],  # None means no limit\n",
    "    'clf__C': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cc7fef32-a5ee-4c93-8f62-8c5a2a640b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = df['Description']  # Features\n",
    "y_grid = df['next_year_gdp_grow_dummy']  # Target variable\n",
    "y_grid = y_grid.reset_index(drop=True) # Reset the index of y to make it align with integer locations\n",
    "X_grid = X_grid.reset_index(drop=True) # Reset the index of y to make it align with integer locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60cd00",
   "metadata": {},
   "source": [
    "### Jointly find the best parameters for both feature extraction and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "86924bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
      " 'vect__max_df': [0.5, 0.75, 1.0],\n",
      " 'vect__max_features': [None, 1000],\n",
      " 'vect__min_df': [1, 2, 5],\n",
      " 'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]}\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "done in 378.584s\n",
      "\n",
      "Best score: 0.898\n",
      "Best parameters set:\n",
      "\tclf__C: 0.01\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1, error_score='raise')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X_grid,y_grid)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b4677d5a-3b5e-4ebc-a760-68729c236918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Negative Features:\n",
      "         features  coefficients\n",
      "4620       fiscal     -0.097391\n",
      "4591    financial     -0.074971\n",
      "8677      reforms     -0.068894\n",
      "10053  structural     -0.060395\n",
      "7967       policy     -0.052434\n",
      "Top 5 Positive Features:\n",
      "       features  coefficients\n",
      "7640   pandemic      0.035109\n",
      "8623   recovery      0.031989\n",
      "2855      covid      0.028906\n",
      "2892     crisis      0.028180\n",
      "10911     union      0.027001\n"
     ]
    }
   ],
   "source": [
    "# Access the best estimator from grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# get the feature names\n",
    "vect = best_clf.named_steps['vect'] \n",
    "feature_names = vect.get_feature_names_out()\n",
    "\n",
    "# Access the logistic regression model\n",
    "logistic_model = best_clf.named_steps['clf']  # Replace 'clf' with the name used for the logistic regression step in  pipeline\n",
    "\n",
    "# Get the coefficients from the logistic regression model\n",
    "coefficients = logistic_model.coef_[0]\n",
    "\n",
    "\n",
    "# Create a DataFrame of features and their corresponding coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'features': feature_names,\n",
    "    'coefficients': coefficients\n",
    "})\n",
    "\n",
    "# Sort the features by the absolute values of their coefficients\n",
    "top_features = feature_importance.reindex(feature_importance.coefficients.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"Top 5 Negative Features:\")\n",
    "# Display the top 5 features\n",
    "print(top_features.head(5))\n",
    "\n",
    "positive_features = feature_importance[feature_importance['coefficients'] > 0].sort_values(by='coefficients', ascending=False)\n",
    "\n",
    "# Display the top 5 positive features\n",
    "print(\"Top 5 Positive Features:\")\n",
    "print(positive_features.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "82986dbc-cb3f-4256-b3e7-967190a5f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8978040540540541\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       605\n",
      "           1       0.90      1.00      0.95      5315\n",
      "\n",
      "    accuracy                           0.90      5920\n",
      "   macro avg       0.45      0.50      0.47      5920\n",
      "weighted avg       0.81      0.90      0.85      5920\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0  605]\n",
      " [   0 5315]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victoria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Victoria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Victoria\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_clf.predict(X_grid)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_grid, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_grid, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_grid, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "40e4963d-0e8f-4030-9871-e62f52193947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Predicted'] = y_pred  # model predictions\n",
    "df['Actual'] = y_grid     # actual outcomes\n",
    "df['Correct'] = df['Predicted'] == df['Actual']  # True if correct, False if incorrect\n",
    "\n",
    "# Filter out incorrect predictions\n",
    "errors = df[df['Correct'] == False]\n",
    "\n",
    "# Calculate the count of errors per year\n",
    "errors_per_year = errors['Year'].value_counts()\n",
    "\n",
    "# Calculate the total number of predictions per year\n",
    "total_predictions_per_year = df['Year'].value_counts()\n",
    "\n",
    "# Calculate the percentage of false predictions per year\n",
    "percentage_errors_per_year = (errors_per_year / total_predictions_per_year) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "defe3c1d-06f2-4c68-a627-a600ae962490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Years with Highest Percentage of False Predictions:\n",
      "Year\n",
      "2020-01-01    74.688797\n",
      "2021-01-01    62.758621\n",
      "2019-01-01    49.537037\n",
      "2007-01-01    38.700565\n",
      "2015-01-01    16.051661\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sort the percentages in descending order\n",
    "sorted_percentage_errors_per_year = percentage_errors_per_year.sort_values(ascending=False)\n",
    "\n",
    "# Display the top 5 years with the highest error rates\n",
    "top_5_years_errors = sorted_percentage_errors_per_year.head(5)\n",
    "print(\"Top 5 Years with Highest Percentage of False Predictions:\")\n",
    "print(top_5_years_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e24fcb-a01d-468b-9d57-b5b9accb0ba0",
   "metadata": {},
   "source": [
    "### Model Summary and Evaluation\n",
    "- The optimal parameters identified include a regularization strength (clf__C) of 0.01, suggesting a higher degree of regularization helps prevent overfitting and enhances model generalization. For the vectorization process, a maximum document frequency (vect__max_df) of 0.5 efficiently filters out very common terms, while the minimum document frequency (vect__min_df) set to 1 and the absence of a maximum feature limit (vect__max_features: None) ensure that all potentially informative terms are considered. The choice of unigram tokens (vect__ngram_range: (1, 1)) confirms that single words provide sufficient predictive power in this context.riable on model decisions.\r\n",
    "\r\n",
    "### Conclusion\r\n",
    "- The model is highly effective for the positive class but fails entirely for the negative class. Adjustments are necessary to improve its predictive capabilities across b\n",
    "- For Class 0 (negative gdp growth), the model missed all the correct prediction, as indicat4ed by 0 value of Precision, Recall, F1-Score.\n",
    "- The years with the highest percentages of incorrect predictions were 2020, 2021, 2019, 2007, and 2015. In 2020, the model had the highest error rate, with approximately 74.69% of the predictions being incorrect. This could potentially be attributed to the global impact of the COVID-19 pandemic, which introduced unprecedented economic disruptions that were not typical of the patterns seen in the training data from previous years. The year 2007, which marked the onset of the global financial crisis, had an error rate of 38.70%, underscoring potential difficulties in predicting downturns that are abrupt and driven by complex financial factors.\n",
    "- The model's coefficients reveal how specific terms influence its predictions. \"Fiscal,\" \"financial,\" \"reforms,\" \"structural,\" and \"policy\" have negative values, suggesting that discussions around these topics are associated with adverse outcomes, possibly reflecting concerns or challenges in these areas. Conversely, \"pandemic,\" \"recovery,\" \"covid,\" \"crisis,\" and \"union\" show positive effects, likely capturing effective responses and rebound after facing significant challenges. th classes, enhancing fairness and accuracy.\r\n",
    "mplex models that might capture the class characteristics better.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b56811-1e69-4b6f-ae29-13b2474fce3b",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "- Boosting\n",
    "- Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bad40-edef-4d7b-b1b6-4e51ed9c5945",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Different boosting methods yield different accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ce484f12-ce98-46a4-b85f-cb30da7ec4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1cec0606-50ec-4dea-bb6e-d20c927e20b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8567567567567569"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "dt_scores = cross_val_score(dt, X, y, cv=5)\n",
    "dt_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6dba1b8b-882f-4b37-98b0-a5cb6de6933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score of the mimicked Random Forest: 0.8978040540540541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Mimicking AdaBoost with Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=1, random_state=0)\n",
    "rf_scores = cross_val_score(rf_clf, X, y, cv=5)\n",
    "rf_mean = rf_scores.mean()\n",
    "\n",
    "print(\"Average score of the mimicked Random Forest:\", rf_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b976e968-d7c6-4049-9e44-bbff01d01dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boosting classifier\n",
    "# please check documentation to understand what does \"estimator=None\" mean?\n",
    "clf = AdaBoostClassifier(estimator=None, n_estimators=100, algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "739c5a44-326b-4cb1-bbb3-3e5db8abec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594594594594595"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf65b2f-06c4-4ac0-99b5-ffb30ec16494",
   "metadata": {},
   "source": [
    "## Multi-layer stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4611ca5b-029e-4c77-987e-4e8e7ae9d3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06840363946374095"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "final_layer_rfr = RandomForestRegressor(n_estimators=10, max_features=1, max_leaf_nodes=5,random_state=42)\n",
    "final_layer_gbr = GradientBoostingRegressor(n_estimators=10, max_features=1, max_leaf_nodes=5,random_state=42)\n",
    "final_layer = StackingRegressor(estimators=[('rf', final_layer_rfr),('gbrt', final_layer_gbr)],\n",
    "                                final_estimator=RidgeCV())\n",
    "\n",
    "multi_layer_regressor = StackingRegressor(estimators=[('ridge', RidgeCV()),\n",
    "                                                      ('lasso', LassoCV(random_state=42)),\n",
    "                                                      ('knr', KNeighborsRegressor(n_neighbors=20,metric='euclidean'))],\n",
    "                                          final_estimator=final_layer)\n",
    "\n",
    "multi_layer_regressor.fit(X_train, y_train)\n",
    "multi_layer_regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ad3722a7-f7d5-4604-bc25-6e0697f526db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   6  233]\n",
      " [   4 2125]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.03      0.05       239\n",
      "           1       0.90      1.00      0.95      2129\n",
      "\n",
      "    accuracy                           0.90      2368\n",
      "   macro avg       0.75      0.51      0.50      2368\n",
      "weighted avg       0.87      0.90      0.86      2368\n",
      "\n",
      "ROC AUC Score: 0.511612893082379\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_continuous = multi_layer_regressor.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary based on the threshold\n",
    "y_pred_binary = np.where(y_pred_continuous >= threshold, 1, 0)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report for precision, recall, f1-score, and accuracy\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Calculate ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred_binary)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fed16a-77d9-4e8d-96d1-e9952b1f1636",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation\n",
    "\r\n",
    "- **True Positives (TP)** forpositive next year gdp growth1: 2125\r\n",
    "- **True Negatives (TN)** fonegative next year gdp growth 0:, which is better than the previous model (with value 0). 6\r\n",
    "- **False Positives (FP)**: 23 negative next year gdp growths 0 incorrectly classified  positive next year gdp growths 1)\r\n",
    "- **False Negatives (FN)**:positive next year gdp growthss 1 incorrectly classifie  negative next year gdp growthss 0)\r\n",
    "\r\n",
    "### Classification Report\r\n",
    "\r\n",
    "- **Precision for Class 0**: 0.60\r\n",
    "  - Indicates that 60% of the model's predic negative next year gdp growth  class 0 wer, a large improvement from before. correct.\r\n",
    "- **Recall for Class 0**: 0.03\r\n",
    "  - Only 3% of the actual class 0 instances were correctl, a small improvement from before.this class.\r\n",
    "- **F1-Score for Class 0**: 0.05\r\n",
    "  - The low F1-score for class 0 indicates poor balance between precision and recall, reflecting overall poor performance fo But it is a small improvement from before.r is the majority class.\r\n",
    "\r\n",
    "### ROC AUC Score\r\n",
    "\r\n",
    "- **ROC AUC Score**: 0.5116\r\n",
    "  - The ROC AUC score close to 0.5 suggests that the model has no discriminative ability to distinguish between class 0 and class 1, eq But this is better than previous model, which is equal to 0.5uedictive accuracy across both classes.\r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f50505-17b3-437b-ae34-587c4b2f8293",
   "metadata": {},
   "source": [
    "### NN for a binary classification task\n",
    "\n",
    "Here, I define a neural network (clf_model) using Keras' Sequential model, which allows me to build a model layer by layer. I add a dense (fully connected) layer with 7 neurons, using ReLU (Rectified Linear Unit) as the activation function(ReLU introduces non-linearity to the model, which is crucial because it allows the network to learn more complex patterns). The input shape is set to (30,), indicating that the model expects each input sample to be a 30-dimensional vector. The second dense layer is the output layer with 1 neuron, using a sigmoid(Sigmoid function outputs a value between 0 and 1, which makes it a natural choice for models where I need to predict the probability of an input being classified as one of two classes (0 or 1)) activation function. This setup is typical for binary classification, where the output is the probability of the sample belonging to one of the classes.\n",
    "\n",
    "dense_6 (Dense): The first dense layer with 7 neurons. The output shape (None, 7) implies that the layer outputs a 7-dimensional vector per sample. The batch size is unspecified (hence None), meaning it can vary. Param # indicates the number of parameters in this layer, calculated as (input_features * neurons + bias_units) = (30 * 7 + 7) = 217.\n",
    "\r\n",
    "dense_7 (Dense): The output layer with 1 neuron, resulting in a shape of (None, 1). This layer has 8 parameters, calculated from (neurons_in_previous_layer * neurons_in_this_layer + bias_units) = (7 * 1 + 1) = 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "63b70a4c-0b16-41b2-8386-c4410fad2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6fb973c0-09cf-48d7-964c-25db26825ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras import models, layers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f9392900-9cbf-4ffc-a634-083ca0f717d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3788, 30), (1184, 30), (948, 30))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare data for model training\n",
    "X = X\n",
    "Y = y\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# split data into train/test/validation\n",
    "X_data, X_test, y_data, y_test = train_test_split(X, encoded_Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b2f83d7c-c5ed-4dcd-ae86-f25c733b04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victoria\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define a NN\n",
    "clf_model = Sequential()\n",
    "clf_model.add(Dense(7, input_shape=(30,), activation='relu'))\n",
    "clf_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "58389373-7ddb-4541-8cca-21bc08856772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m217\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225</span> (900.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225\u001b[0m (900.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225</span> (900.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225\u001b[0m (900.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b5094931-23d0-45e9-b516-3d2213b56cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(clf_model, \"binary_classifier.png\") # show_shapes=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7e188140-1055-4aeb-9429-babfccdb346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "27ad450e-f19f-433c-bd3f-f99d4a9a29b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 0.6761 - val_accuracy: 0.8977 - val_loss: 0.5504\n",
      "Epoch 2/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.5393 - val_accuracy: 0.9030 - val_loss: 0.4445\n",
      "Epoch 3/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.4516 - val_accuracy: 0.9030 - val_loss: 0.3862\n",
      "Epoch 4/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3831 - val_accuracy: 0.9030 - val_loss: 0.3527\n",
      "Epoch 5/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.3561 - val_accuracy: 0.9030 - val_loss: 0.3318\n",
      "Epoch 6/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3348 - val_accuracy: 0.9030 - val_loss: 0.3202\n",
      "Epoch 7/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.3314 - val_accuracy: 0.9019 - val_loss: 0.3132\n",
      "Epoch 8/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.3028 - val_accuracy: 0.9008 - val_loss: 0.3106\n",
      "Epoch 9/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3237 - val_accuracy: 0.9019 - val_loss: 0.3073\n",
      "Epoch 10/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.3285 - val_accuracy: 0.9030 - val_loss: 0.3059\n",
      "Epoch 11/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.3037 - val_accuracy: 0.9019 - val_loss: 0.3050\n",
      "Epoch 12/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2787 - val_accuracy: 0.9008 - val_loss: 0.3053\n",
      "Epoch 13/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3110 - val_accuracy: 0.9040 - val_loss: 0.3027\n",
      "Epoch 14/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2980 - val_accuracy: 0.9051 - val_loss: 0.3024\n",
      "Epoch 15/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.3076 - val_accuracy: 0.9061 - val_loss: 0.3020\n",
      "Epoch 16/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3099 - val_accuracy: 0.9051 - val_loss: 0.3020\n",
      "Epoch 17/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2838 - val_accuracy: 0.9040 - val_loss: 0.3018\n",
      "Epoch 18/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.2927 - val_accuracy: 0.9040 - val_loss: 0.3016\n",
      "Epoch 19/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2905 - val_accuracy: 0.9040 - val_loss: 0.3012\n",
      "Epoch 20/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2912 - val_accuracy: 0.9051 - val_loss: 0.3010\n",
      "Epoch 21/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3018 - val_accuracy: 0.9051 - val_loss: 0.3010\n",
      "Epoch 22/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2897 - val_accuracy: 0.9051 - val_loss: 0.3005\n",
      "Epoch 23/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2908 - val_accuracy: 0.9040 - val_loss: 0.3015\n",
      "Epoch 24/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2744 - val_accuracy: 0.9040 - val_loss: 0.3009\n",
      "Epoch 25/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.3044 - val_accuracy: 0.9040 - val_loss: 0.3004\n",
      "Epoch 26/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3006 - val_accuracy: 0.9051 - val_loss: 0.3000\n",
      "Epoch 27/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2709 - val_accuracy: 0.9061 - val_loss: 0.3011\n",
      "Epoch 28/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2857 - val_accuracy: 0.9051 - val_loss: 0.3002\n",
      "Epoch 29/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2929 - val_accuracy: 0.9051 - val_loss: 0.3002\n",
      "Epoch 30/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.3064 - val_accuracy: 0.9040 - val_loss: 0.2999\n",
      "Epoch 31/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2936 - val_accuracy: 0.9051 - val_loss: 0.2999\n",
      "Epoch 32/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2739 - val_accuracy: 0.9061 - val_loss: 0.3004\n",
      "Epoch 33/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2993 - val_accuracy: 0.9040 - val_loss: 0.2994\n",
      "Epoch 34/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2762 - val_accuracy: 0.9061 - val_loss: 0.3003\n",
      "Epoch 35/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3029 - val_accuracy: 0.9061 - val_loss: 0.2996\n",
      "Epoch 36/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2856 - val_accuracy: 0.9061 - val_loss: 0.2995\n",
      "Epoch 37/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2847 - val_accuracy: 0.9051 - val_loss: 0.2994\n",
      "Epoch 38/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2792 - val_accuracy: 0.9051 - val_loss: 0.3000\n",
      "Epoch 39/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2871 - val_accuracy: 0.9030 - val_loss: 0.2990\n",
      "Epoch 40/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2948 - val_accuracy: 0.9051 - val_loss: 0.2994\n",
      "Epoch 41/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2766 - val_accuracy: 0.9051 - val_loss: 0.2994\n",
      "Epoch 42/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2948 - val_accuracy: 0.9051 - val_loss: 0.2994\n",
      "Epoch 43/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2732 - val_accuracy: 0.9040 - val_loss: 0.2995\n",
      "Epoch 44/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2835 - val_accuracy: 0.9040 - val_loss: 0.2998\n",
      "Epoch 45/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2771 - val_accuracy: 0.9040 - val_loss: 0.3003\n",
      "Epoch 46/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2933 - val_accuracy: 0.9030 - val_loss: 0.2997\n",
      "Epoch 47/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2951 - val_accuracy: 0.9040 - val_loss: 0.2999\n",
      "Epoch 48/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.3047 - val_accuracy: 0.9040 - val_loss: 0.2992\n",
      "Epoch 49/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2951 - val_accuracy: 0.9030 - val_loss: 0.3001\n",
      "Epoch 50/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2884 - val_accuracy: 0.9030 - val_loss: 0.2997\n",
      "Epoch 51/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.3023 - val_accuracy: 0.9030 - val_loss: 0.3000\n",
      "Epoch 52/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2803 - val_accuracy: 0.9030 - val_loss: 0.3002\n",
      "Epoch 53/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2961 - val_accuracy: 0.9040 - val_loss: 0.3001\n",
      "Epoch 54/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2839 - val_accuracy: 0.9030 - val_loss: 0.3001\n",
      "Epoch 55/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2825 - val_accuracy: 0.9030 - val_loss: 0.3002\n",
      "Epoch 56/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2880 - val_accuracy: 0.9008 - val_loss: 0.3003\n",
      "Epoch 57/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2852 - val_accuracy: 0.9040 - val_loss: 0.2993\n",
      "Epoch 58/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2816 - val_accuracy: 0.9040 - val_loss: 0.2996\n",
      "Epoch 59/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2793 - val_accuracy: 0.9030 - val_loss: 0.2998\n",
      "Epoch 60/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2783 - val_accuracy: 0.9008 - val_loss: 0.3004\n",
      "Epoch 61/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.2842 - val_accuracy: 0.9019 - val_loss: 0.2997\n",
      "Epoch 62/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2648 - val_accuracy: 0.9019 - val_loss: 0.3003\n",
      "Epoch 63/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2890 - val_accuracy: 0.9008 - val_loss: 0.3002\n",
      "Epoch 64/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2885 - val_accuracy: 0.9019 - val_loss: 0.3004\n",
      "Epoch 65/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2903 - val_accuracy: 0.9008 - val_loss: 0.3001\n",
      "Epoch 66/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2882 - val_accuracy: 0.9008 - val_loss: 0.2998\n",
      "Epoch 67/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2677 - val_accuracy: 0.8987 - val_loss: 0.3008\n",
      "Epoch 68/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2832 - val_accuracy: 0.9019 - val_loss: 0.3001\n",
      "Epoch 69/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2769 - val_accuracy: 0.8998 - val_loss: 0.2997\n",
      "Epoch 70/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2837 - val_accuracy: 0.9008 - val_loss: 0.2998\n",
      "Epoch 71/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2935 - val_accuracy: 0.8998 - val_loss: 0.3007\n",
      "Epoch 72/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2942 - val_accuracy: 0.8998 - val_loss: 0.2996\n",
      "Epoch 73/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2829 - val_accuracy: 0.8987 - val_loss: 0.3003\n",
      "Epoch 74/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2812 - val_accuracy: 0.8987 - val_loss: 0.2995\n",
      "Epoch 75/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2743 - val_accuracy: 0.8987 - val_loss: 0.3006\n",
      "Epoch 76/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2692 - val_accuracy: 0.8987 - val_loss: 0.3005\n",
      "Epoch 77/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2734 - val_accuracy: 0.8987 - val_loss: 0.3009\n",
      "Epoch 78/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2566 - val_accuracy: 0.8987 - val_loss: 0.3008\n",
      "Epoch 79/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2796 - val_accuracy: 0.8987 - val_loss: 0.3000\n",
      "Epoch 80/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2700 - val_accuracy: 0.8987 - val_loss: 0.3006\n",
      "Epoch 81/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2660 - val_accuracy: 0.8987 - val_loss: 0.3004\n",
      "Epoch 82/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2714 - val_accuracy: 0.8998 - val_loss: 0.3009\n",
      "Epoch 83/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.2901 - val_accuracy: 0.8987 - val_loss: 0.2998\n",
      "Epoch 84/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.2816 - val_accuracy: 0.9008 - val_loss: 0.3005\n",
      "Epoch 85/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2735 - val_accuracy: 0.8987 - val_loss: 0.2999\n",
      "Epoch 86/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2851 - val_accuracy: 0.9008 - val_loss: 0.3001\n",
      "Epoch 87/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2863 - val_accuracy: 0.8998 - val_loss: 0.2999\n",
      "Epoch 88/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2925 - val_accuracy: 0.8998 - val_loss: 0.2999\n",
      "Epoch 89/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2850 - val_accuracy: 0.9008 - val_loss: 0.3008\n",
      "Epoch 90/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2614 - val_accuracy: 0.8998 - val_loss: 0.3005\n",
      "Epoch 91/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2736 - val_accuracy: 0.8998 - val_loss: 0.3007\n",
      "Epoch 92/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.2757 - val_accuracy: 0.8998 - val_loss: 0.3005\n",
      "Epoch 93/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2644 - val_accuracy: 0.8987 - val_loss: 0.3015\n",
      "Epoch 94/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2681 - val_accuracy: 0.9008 - val_loss: 0.3005\n",
      "Epoch 95/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2901 - val_accuracy: 0.8987 - val_loss: 0.3001\n",
      "Epoch 96/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.2872 - val_accuracy: 0.9008 - val_loss: 0.3015\n",
      "Epoch 97/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2728 - val_accuracy: 0.8998 - val_loss: 0.3011\n",
      "Epoch 98/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2778 - val_accuracy: 0.8998 - val_loss: 0.3011\n",
      "Epoch 99/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2844 - val_accuracy: 0.8998 - val_loss: 0.3006\n",
      "Epoch 100/100\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2584 - val_accuracy: 0.8977 - val_loss: 0.3014\n"
     ]
    }
   ],
   "source": [
    "history = clf_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "99ed6bf0-d180-4b2a-bd18-23ef29b610ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance(flag):\n",
    "    history_dict = history.history\n",
    "    epochs = range(1, len(history_dict[\"loss\"]) + 1)\n",
    "\n",
    "    plt.plot(epochs, history_dict[flag], \"bo\", label=\"Training \"+flag)\n",
    "    plt.plot(epochs, history_dict[\"val_\"+flag], \"b\", label=\"Validation \"+flag)\n",
    "    plt.title(\"Training and validation \"+flag)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "08eab716-3bec-4b77-af68-f2e6651417d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_performance(flag = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e6922ef6-1741-41b2-a954-36ec13b7d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_performance(flag = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "36f711b2-2b6d-4269-89e5-eefd63d7d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.3052 \n",
      "test_acc: 0.895\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance regarding accuracy\n",
    "test_loss, test_acc = clf_model.evaluate(X_test, y_test)\n",
    "print(f\"test_acc: {np.round(test_acc,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0c691b8d-948d-435b-93b2-81a4809bbdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.12      0.19       120\n",
      "           1       0.91      0.98      0.94      1064\n",
      "\n",
      "    accuracy                           0.90      1184\n",
      "   macro avg       0.67      0.55      0.57      1184\n",
      "weighted avg       0.86      0.90      0.87      1184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "y_pred_prob = clf_model.predict(X_test)\n",
    "y_pred_labels = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "457b93cb-618f-4e70-987b-9d92b5c61047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  15  105]\n",
      " [  19 1045]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "63974b70-6de0-485a-ab50-0a9a0c7a34ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5535714285714286"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_pred_labels)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6ab16-e84b-4045-bd06-208941cc991b",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "\n",
    "#### Interpretation of Training and Validation Loss Graph\n",
    "At the beginning, both training and validation losses decrease sharply. This indicates that the model is quickly learning from the training data. The rapid improvement suggests that the initial weights were quite far from the optimal, and early adjustments during training significantly improve the model's performance. After the initial sharp decrease, both the training and validation losses begin to stabilize. This stabilization suggests that the model is reaching a point where further learning on the training set does not significantly decrease the error on the validation set. The closeness of the training and validation loss throughout the training process suggests good generalization. There isn't a significant gap between the two, which often indicates that the model is not overfitting.\n",
    "\n",
    "####  Training and Validation Accuracy Interpretation\n",
    "Initially, there is a sharp increase in both training and validation accuracy. The training accuracy quickly reaches a high level and remains stable for the remainder of the training process.  The relatively small gap between training and validation accuracy through most of the epochs indicates good model generalization. The relatively small gap between training and validation accuracy through most of the epochs indicates good model generalization. There is no significant divergence that might suggest overfitting.\n",
    "\n",
    "The accuracies stabilize after around 20 epochs, with little to no improvement in validation accuracy. This suggests that subsequent training does little to enhance the model’s ability to perform on unseen data, which might be an indicator to employ early stopping in future training sessions to save computational resources and prevent potential overfitting.\n",
    "\n",
    "#### F1, Recall, ROC AUC\n",
    "The updated evaluation metrics indicate an improvement in model performance to correctly classify the (class 0). The model shows only a modest improvement in F1 and a slight increase in recall, achieving a F1 of 0.19 and a recall of 0.12. The ROC AUC score of 0.55 shows only a slight improvement from random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "24ebf56b-c772-49aa-8dfa-9e1a57a1538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to calculate permutation feature importance for a DataFrame\n",
    "def permutation_importance(model, X_val, y_val, metric=accuracy_score):\n",
    "    baseline_score = metric(y_val, model.predict(X_val) > 0.5)\n",
    "    importances = []\n",
    "    \n",
    "    # Convert DataFrame to numpy array for processing if not already\n",
    "    X_val_np = X_val.to_numpy() if isinstance(X_val, pd.DataFrame) else X_val\n",
    "    \n",
    "    for i in range(X_val_np.shape[1]):\n",
    "        save = X_val_np[:, i].copy()\n",
    "        np.random.shuffle(X_val_np[:, i])\n",
    "        shuffled_score = metric(y_val, model.predict(X_val_np) > 0.5)\n",
    "        X_val_np[:, i] = save\n",
    "        importances.append(baseline_score - shuffled_score)\n",
    "    \n",
    "    return np.array(importances)\n",
    "\n",
    "# Calculate importances\n",
    "feature_importances = permutation_importance(clf_model, X_val, y_val)\n",
    "top_ten_features = np.argsort(feature_importances)[::-1][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d1737871-ad29-4051-873b-53365b236a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features by Importance:\n",
      "Index(['crisi', 'pandem', 'invest', 'recoveri', 'need', 'disput', 'challeng',\n",
      "       'sustain', 'strengthen', 'import'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = X.columns[top_ten_features]\n",
    "print(\"Top 10 Features by Importance:\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c845b3-8ddf-465f-9e9d-685a672bd4c8",
   "metadata": {},
   "source": [
    "The top ten features by importance in the model encompass a mix of economic, political, and social indicators that reflect key drivers of outcomes in various contexts. Features like \"strengthen,\" \"invest,\" and \"import\" highlight a focus on growth and trade activity, while terms like \"pandemic\" and \"crisis\" underscore the model’s sensitivity to emergency or exceptional conditions. \"challeng\" and \"need\" suggest attention to policy changes and potential hazards. The presence of \"recoveri\" indicates economic health recovery. Overall, these features illustrate the model's capability to incorporate critical and timely data, informing decisions across multiple domains effectively.\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4303c-b28f-402c-9df0-0cd314c79c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
